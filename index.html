<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>WebRTC Screen Mirroring</title>
    <style>
        body { 
            margin: 0; 
            background-color: #000; 
            color: white; 
            font-family: Arial, sans-serif;
        }
        #remoteVideo {
            width: 100vw;
            height: 100vh;
            object-fit: contain;
            background: #000;
        }
        #status {
            position: absolute; 
            top: 20px; 
            left: 20px; 
            font-size: 1.2em;
            background: rgba(0,0,0,0.7); 
            padding: 10px 15px; 
            border-radius: 5px; 
            z-index: 100;
        }
    </style>
</head>
<body>
<div id="status">Connecting...</div>
<video id="remoteVideo" autoplay playsinline></video>

<script src="https://www.gstatic.com/cast/sdk/libs/caf_receiver/v3/cast_receiver_framework.js"></script>
<script>
    const statusEl = document.getElementById('status');
    const remoteVideo = document.getElementById('remoteVideo');
    const NAMESPACE = 'urn:x-cast:com.xxx.screenmirroring';
    let peerConnection = null;
    let context = null;

    try {
        context = cast.framework.CastReceiverContext.getInstance();
        const castReceiverOptions = new cast.framework.CastReceiverOptions();
        castReceiverOptions.disableIdleTimeout = true;
        castReceiverOptions.maxInactivity = 3600;

        context.addCustomMessageListener(NAMESPACE, function(customEvent) {
            try {
                let data = customEvent.data;
                if (typeof data === 'string') {
                    data = JSON.parse(data);
                }

                if (data.type === 'offer') {
                    handleOffer(data);
                } else if (data.type === 'ice_candidate') {
                    handleIceCandidate(data);
                }
            } catch (e) {
                console.error('Message processing error:', e);
            }
        });

        context.addEventListener(cast.framework.system.EventType.READY, () => {
            statusEl.textContent = 'Ready';
            console.log('Receiver ready');
        });

        context.addEventListener(cast.framework.system.EventType.SENDER_CONNECTED, (event) => {
            statusEl.textContent = 'Connected - Waiting for stream...';
            console.log('Sender connected:', event.senderId);
        });

        context.addEventListener(cast.framework.system.EventType.SENDER_DISCONNECTED, () => {
            statusEl.textContent = 'Disconnected';
            if (peerConnection) {
                peerConnection.close();
                peerConnection = null;
            }
            remoteVideo.srcObject = null;
        });

        context.start(castReceiverOptions);

    } catch (e) {
        console.error('Init error:', e);
        statusEl.textContent = 'Error: ' + e.message;
    }

    async function handleOffer(data) {
        try {
            console.log('Handling offer');
            
            const configuration = {
                iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
                bundlePolicy: 'max-bundle',
                rtcpMuxPolicy: 'require'
            };
            peerConnection = new RTCPeerConnection(configuration);

            let videoReady = false;
            let audioReady = false;
            let streamSet = false;

            // CRITICAL: Handle tracks as they arrive
            peerConnection.ontrack = (event) => {
                console.log('Track received:', event.track.kind);
                
                if (event.track.kind === 'video') videoReady = true;
                if (event.track.kind === 'audio') audioReady = true;

                if (event.streams && event.streams[0]) {
                    // Set stream immediately on first track
                    if (!streamSet) {
                        console.log('Setting stream with', event.streams[0].getTracks().length, 'track(s)');
                        remoteVideo.srcObject = event.streams[0];
                        streamSet = true;
                        
                        // CRITICAL FIX: Force unmute and set volume BEFORE play
                        remoteVideo.muted = false;
                        remoteVideo.volume = 1.0;
                        
                        // Try to play immediately
                        remoteVideo.play().then(() => {
                            console.log('Playback started');
                            statusEl.textContent = 'Playing';
                            console.log('Audio tracks:', remoteVideo.srcObject.getAudioTracks().length);
                            console.log('Video muted:', remoteVideo.muted, 'Volume:', remoteVideo.volume);
                            
                            // ADDITIONAL FIX: Force audio track to be enabled
                            remoteVideo.srcObject.getAudioTracks().forEach(track => {
                                track.enabled = true;
                                console.log('Audio track enabled:', track.id, track.readyState);
                            });
                        }).catch(e => console.error('Play failed:', e));
                    }
                }
            };

            peerConnection.oniceconnectionstatechange = () => {
                console.log('ICE state:', peerConnection.iceConnectionState);
                if (peerConnection.iceConnectionState === 'connected') {
                    statusEl.textContent = 'Streaming';
                    
                    // BACKUP: Ensure audio is playing after connection
                    if (remoteVideo.srcObject) {
                        remoteVideo.muted = false;
                        remoteVideo.volume = 1.0;
                        remoteVideo.srcObject.getAudioTracks().forEach(track => {
                            track.enabled = true;
                        });
                    }
                }
            };

            peerConnection.onicecandidate = (event) => {
                if (event.candidate) {
                    sendMessage({
                        type: 'ice_candidate',
                        candidate: event.candidate.candidate,
                        sdpMid: event.candidate.sdpMid,
                        sdpMLineIndex: event.candidate.sdpMLineIndex
                    });
                }
            };

            await peerConnection.setRemoteDescription(new RTCSessionDescription({
                type: 'offer',
                sdp: data.sdp
            }));
            console.log('Remote description set');

            const answer = await peerConnection.createAnswer();
            await peerConnection.setLocalDescription(answer);
            console.log('Answer created');

            sendMessage({ type: 'answer', sdp: answer.sdp });

        } catch (e) {
            console.error('Offer handling error:', e);
            statusEl.textContent = 'Error: ' + e.message;
        }
    }

    async function handleIceCandidate(data) {
        try {
            if (peerConnection && data.candidate) {
                await peerConnection.addIceCandidate(new RTCIceCandidate({
                    candidate: data.candidate,
                    sdpMid: data.sdpMid,
                    sdpMLineIndex: data.sdpMLineIndex
                }));
            }
        } catch (e) {
            console.error('ICE candidate error:', e);
        }
    }

    function sendMessage(messageObject) {
        try {
            const messageStr = JSON.stringify(messageObject);
            context.sendCustomMessage(NAMESPACE, undefined, messageStr);
        } catch (e) {
            console.error('Send message error:', e);
        }
    }

    // FIX: Add user interaction handler for audio (some browsers require this)
    remoteVideo.addEventListener('loadedmetadata', () => {
        console.log('Video metadata loaded');
        console.log('Dimensions:', remoteVideo.videoWidth, 'x', remoteVideo.videoHeight);
        console.log('Duration:', remoteVideo.duration);
        
        // Force unmute again when metadata loads
        remoteVideo.muted = false;
        remoteVideo.volume = 1.0;
    });

    remoteVideo.addEventListener('canplay', () => {
        console.log('Video can play');
        // Ensure audio is enabled
        if (remoteVideo.srcObject) {
            remoteVideo.srcObject.getAudioTracks().forEach(track => {
                console.log('Audio track on canplay:', track.id, 'enabled:', track.enabled, 'muted:', track.muted);
                track.enabled = true;
            });
        }
    });
</script>
</body>
</html>

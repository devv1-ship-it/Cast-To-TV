<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Cast To TV - WebRTC Screen Mirroring</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            background-color: #000;
            overflow: hidden;
        }
        #video-container {
            width: 100vw;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            background: #000;
        }
        #remoteVideo {
            width: 100%;
            height: 100%;
            object-fit: contain; /* Ensures the whole screen fits */
            background: #000;
        }
        #status {
            position: absolute;
            top: 20px;
            left: 20px;
            color: white;
            font-family: Arial, sans-serif;
            font-size: 18px;
            background: rgba(0,0,0,0.7);
            padding: 10px 20px;
            border-radius: 5px;
            z-index: 1000;
        }
        #stats {
            position: absolute;
            top: 60px;
            left: 20px;
            color: #0f0;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            background: rgba(0,0,0,0.7);
            padding: 5px 10px;
            border-radius: 5px;
            z-index: 1000;
        }
    </style>
</head>
<body>
<div id="status">Initializing WebRTC...</div>
<div id="stats">Waiting for connection...</div>
<div id="video-container">
    <!-- 'autoplay' and 'playsinline' are critical for mobile/browser playback policies -->
    <video id="remoteVideo" autoplay playsinline></video>
</div>

<!-- Load the Cast Application Framework (CAF) Receiver SDK -->
<script src="https://www.gstatic.com/cast/sdk/libs/caf_receiver/v3/cast_receiver_framework.js"></script>

<!-- Custom WebRTC Logic -->
<script>
    const context = cast.framework.CastReceiverContext.getInstance();
    const statusEl = document.getElementById('status');
    const statsEl = document.getElementById('stats');
    const remoteVideo = document.getElementById('remoteVideo');

    // This NAMESPACE MUST match the one in your Android code (ScreenCaptureServiceWebRTC)
    const NAMESPACE = 'urn:x-cast:com.xxx.screenmirroring';

    // WebRTC variables
    let peerConnection = null;
    let statsInterval = null;
    let lastBytesReceived = 0;
    let lastTimestamp = Date.now();

    // Audio playback for system audio
    let audioContext = null;
    let audioQueue = [];
    let isPlayingAudio = false;
    let nextStartTime = 0;

    console.log('=== WebRTC Cast Receiver Initializing ===');

    // Initialize Web Audio API
    function initAudioContext() {
        if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            console.log('âœ“ Audio context initialized, sample rate:', audioContext.sampleRate);
        }
    }

    // Play audio chunk received from Android
    function playAudioChunk(base64Data, sampleRate, channels) {
        try {
            if (!audioContext) {
                initAudioContext();
            }

            // Decode base64 to ArrayBuffer
            const binaryString = atob(base64Data);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }

            // Convert to Int16Array (PCM 16-bit)
            const int16Array = new Int16Array(bytes.buffer);
            
            // Convert to Float32Array for Web Audio API
            const float32Array = new Float32Array(int16Array.length);
            for (let i = 0; i < int16Array.length; i++) {
                float32Array[i] = int16Array[i] / 32768.0; // Normalize to -1.0 to 1.0
            }

            // Create audio buffer
            const samplesPerChannel = float32Array.length / channels;
            const audioBuffer = audioContext.createBuffer(channels, samplesPerChannel, sampleRate);

            // Fill buffer with audio data
            if (channels === 2) {
                const leftChannel = audioBuffer.getChannelData(0);
                const rightChannel = audioBuffer.getChannelData(1);
                for (let i = 0; i < samplesPerChannel; i++) {
                    leftChannel[i] = float32Array[i * 2];
                    rightChannel[i] = float32Array[i * 2 + 1];
                }
            } else {
                const channelData = audioBuffer.getChannelData(0);
                channelData.set(float32Array);
            }

            // Schedule playback
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);

            const currentTime = audioContext.currentTime;
            if (nextStartTime < currentTime) {
                nextStartTime = currentTime;
            }

            source.start(nextStartTime);
            nextStartTime += audioBuffer.duration;

        } catch (error) {
            console.error('Error playing audio chunk:', error);
        }
    }

    // ====================================================================
    // Custom Message Listener (Handling Signaling)
    // ====================================================================
    context.addCustomMessageListener(NAMESPACE, function(customEvent) {
        try {
            let data = customEvent.data;
            // Robustly parse the message (Cast SDK sometimes sends it as an escaped string)
            if (typeof data === 'string') {
                try {
                    data = JSON.parse(data);
                } catch(e) {
                     // The message might be a stringified JSON object, try one more time
                     data = JSON.parse(data.trim('"').replace(/\\/g, ""));
                }
            }

            console.log('Received message type:', data.type);

            if (data.type === 'offer') {
                handleOffer(data);
            } else if (data.type === 'ice_candidate') {
                handleIceCandidate(data);
            } else if (data.type === 'audio') {
                // Handle incoming audio data
                console.log('Received audio data');
                playAudioChunk(data.payload.data, data.payload.sampleRate, data.payload.channels);
            }
        } catch (error) {
            console.error('Error processing message:', error);
            statusEl.textContent = 'Error: ' + error.message;
        }
    });

    // ====================================================================
    // WebRTC Offer/Answer and Connection Logic
    // ====================================================================
    async function handleOffer(data) {
        try {
            console.log('Handling offer from sender');
            statusEl.textContent = 'ðŸ“¡ Setting up WebRTC connection...';

            // 1. Create Peer Connection
            const configuration = {
                iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
                sdpSemantics: 'unified-plan'
            };
            peerConnection = new RTCPeerConnection(configuration);

            // 2. Handle Incoming Tracks (Video + Audio)
            peerConnection.ontrack = (event) => {
                console.log('âœ“ Received track:', event.track.kind);

                if (event.streams && event.streams[0]) {
                    console.log('Attaching stream to video element...');
                    remoteVideo.srcObject = event.streams[0];

                    // Force video playback, addressing browser autoplay policies.
                    remoteVideo.muted = false; // Try with audio first
                    remoteVideo.play().then(() => {
                        console.log('âœ“âœ“âœ“ Video playback started successfully (with sound)!');
                        statusEl.textContent = 'âœ… Screen Mirroring Active';
                        startStatsMonitoring();
                    }).catch(err => {
                        console.error('âœ— Playback failed, trying again MUTED:', err);
                        // If it fails (common policy restriction), try again muted.
                        remoteVideo.muted = true;
                        remoteVideo.play().then(() => {
                            console.log('âœ“âœ“âœ“ Video playback started (muted)!');
                            statusEl.textContent = 'âœ… Screen Mirroring Active (Audio Muted)';
                            startStatsMonitoring();
                        }).catch(err2 => {
                            console.error('âœ— Playback failed even when muted:', err2);
                            statusEl.textContent = 'Error: Could not play video.';
                        });
                    });
                }
            };

            // 3. Handle Other Connection Events (Logging)
            peerConnection.oniceconnectionstatechange = () => {
                const state = peerConnection.iceConnectionState;
                console.log('ICE Connection State:', state);
                if (state === 'connected' || state === 'completed') {
                    statusEl.textContent = 'âœ… Connected - Waiting for video...';
                } else if (state === 'disconnected') {
                    statusEl.textContent = 'âš ï¸ Connection lost';
                } else if (state === 'failed') {
                    statusEl.textContent = 'âŒ Connection failed';
                    stopStatsMonitoring();
                } else if (state === 'checking') {
                    statusEl.textContent = 'ðŸ”„ Connecting...';
                }
            };
            peerConnection.onicecandidate = (event) => {
                if (event.candidate) {
                    sendIceCandidate(event.candidate);
                }
            };

            // 4. Set Remote Description (Offer) and Create Answer
            await peerConnection.setRemoteDescription(new RTCSessionDescription({
                type: 'offer',
                sdp: data.sdp
            }));
            console.log('âœ“ Remote description set');

            const answer = await peerConnection.createAnswer();
            await peerConnection.setLocalDescription(answer);
            console.log('âœ“ Local description (answer) set');

            // 5. Send Answer Back to Sender
            sendAnswer(answer);

        } catch (error) {
            console.error('âœ— Error handling offer:', error);
            statusEl.textContent = 'Fatal Error: ' + error.message;
        }
    }

    async function handleIceCandidate(data) {
        try {
            if (peerConnection && data.candidate) {
                await peerConnection.addIceCandidate(new RTCIceCandidate({
                    candidate: data.candidate,
                    sdpMid: data.sdpMid,
                    sdpMLineIndex: data.sdpMLineIndex
                }));
                console.log('âœ“ Added ICE candidate from sender');
            }
        } catch (error) {
            console.error('Error adding ICE candidate:', error);
        }
    }

    // ====================================================================
    // Signaling (Sending Messages via Cast Channel)
    // ====================================================================
    function sendAnswer(answer) {
        sendMessage({ type: 'answer', sdp: answer.sdp });
        console.log('âœ“ Sent WebRTC answer to sender');
    }

    function sendIceCandidate(candidate) {
        sendMessage({
            type: 'ice_candidate',
            candidate: candidate.candidate,
            sdpMid: candidate.sdpMid,
            sdpMLineIndex: candidate.sdpMLineIndex
        });
    }

    function sendMessage(messageObject) {
        try {
            const messageString = JSON.stringify(messageObject);
            // Use the context to send the message back to the Android sender
            context.sendCustomMessage(NAMESPACE, undefined, messageString);
        } catch (error) {
            console.error('Error sending message:', error, messageObject);
        }
    }

    // ====================================================================
    // Stats and Monitoring
    // ====================================================================
    function startStatsMonitoring() {
        if (statsInterval) return;
        statsEl.textContent = 'Monitoring...';

        let lastBytesReceived = 0;
        let lastTimestamp = Date.now();
        let videoTrackId = remoteVideo.srcObject.getVideoTracks()[0].id;

        statsInterval = setInterval(async () => {
            if (!peerConnection) return;

            try {
                const stats = await peerConnection.getStats();
                let fps = 0;
                let bitrate = 0;
                let resolution = 'N/A';
                let packetsLost = 0;
                let jitter = 0;

                stats.forEach(report => {
                    if (report.type === 'inbound-rtp' && report.mediaType === 'video') {
                        fps = report.framesPerSecond || 0;
                        packetsLost = report.packetsLost || 0;
                        jitter = (report.jitter * 1000).toFixed(1) || 0; // ms

                        const now = Date.now();
                        const timeDiff = (now - lastTimestamp) / 1000;
                        const bytesDiff = (report.bytesReceived || 0) - lastBytesReceived;
                        bitrate = Math.round((bytesDiff * 8) / timeDiff / 1000); // Kbps

                        lastBytesReceived = report.bytesReceived || 0;
                        lastTimestamp = now;
                    }
                    if (report.type === 'track' && report.trackIdentifier === videoTrackId) {
                        resolution = `${report.frameWidth || 'N/A'}x${report.frameHeight || 'N/A'}`;
                    }
                });

                statsEl.innerHTML = `FPS: ${fps.toFixed(0)} | ${bitrate} Kbps | ${resolution}<br>Lost: ${packetsLost} | Jitter: ${jitter}ms`;
            } catch (error) {
                // console.error('Error getting stats:', error); // Silence this to prevent console clutter
            }
        }, 1000);
    }

    function stopStatsMonitoring() {
        if (statsInterval) {
            clearInterval(statsInterval);
            statsInterval = null;
        }
        statsEl.textContent = 'Waiting for connection...';
    }

    // ====================================================================
    // Receiver Lifecycle (Cast SDK)
    // ====================================================================
    context.addEventListener(cast.framework.system.EventType.SENDER_CONNECTED, function(event) {
        console.log('âœ“ Sender connected:', event.senderId);
        statusEl.textContent = 'Device Connected - Waiting for stream...';
    });

    context.addEventListener(cast.framework.system.EventType.SENDER_DISCONNECTED, function(event) {
        console.log('Sender disconnected');
        statusEl.textContent = 'Device Disconnected';
        stopStatsMonitoring();
        remoteVideo.srcObject = null; // Clear video
        if (peerConnection) {
            peerConnection.close();
            peerConnection = null;
        }
    });

    context.addEventListener(cast.framework.system.EventType.READY, function(event) {
        console.log('âœ“ Receiver ready');
        statusEl.textContent = 'Ready - Waiting for connection...';
    });

    // Start receiver
    try {
        context.start(castReceiverOptions);
        console.log('=== âœ“âœ“âœ“ WebRTC Cast receiver started successfully ===');
    } catch (error) {
        console.error('=== âœ—âœ—âœ— FAILED to start receiver ===', error);
        statusEl.textContent = 'FAILED: ' + error.message;
        document.body.style.backgroundColor = '#ff0000';
    }
</script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>MSE Screen Mirroring</title>
    <style>
        body { margin: 0; background-color: black; }
        video { width: 100vw; height: 100vh; object-fit: contain; }
    </style>
</head>
<body>
    <video id="remoteVideo"></video>
    <script src="//www.gstatic.com/cast/sdk/libs/caf_receiver/latest/cast_receiver_framework.js"></script>
    <script>
        window.__onGCastApiAvailable = function(isAvailable) {
            if (isAvailable) initializeApp();
        };

        function initializeApp() {
            const remoteVideo = document.getElementById('remoteVideo');
            const NAMESPACE = 'urn:x-cast:com.xxx.screenmirroring';
            
            const context = cast.framework.CastReceiverContext.getInstance();
            const castReceiverOptions = new cast.framework.CastReceiverOptions();
            castReceiverOptions.disableIdleTimeout = true;

            let mediaSource = new MediaSource();
            remoteVideo.src = URL.createObjectURL(mediaSource);

            let videoSourceBuffer;
            let audioSourceBuffer;
            let videoQueue = [];
            let audioQueue = [];

            mediaSource.addEventListener('sourceopen', () => {
                console.log('MediaSource is open. Ready for data.');
                // Codecs must match what MediaCodec produces on Android
                videoSourceBuffer = mediaSource.addSourceBuffer('video/mp4; codecs="avc1.42E01E"');
                audioSourceBuffer = mediaSource.addSourceBuffer('audio/mp4; codecs="mp4a.40.2"');

                videoSourceBuffer.addEventListener('updateend', () => processQueue(videoQueue, videoSourceBuffer));
                audioSourceBuffer.addEventListener('updateend', () => processQueue(audioQueue, audioSourceBuffer));
            });

            function processQueue(queue, buffer) {
                if (queue.length > 0 && !buffer.updating) {
                    buffer.appendBuffer(queue.shift());
                }
            }
            
            context.addCustomMessageListener(NAMESPACE, (customEvent) => {
                try {
                    const message = customEvent.data;
                    // We expect binary data now, not JSON
                    if (message instanceof ArrayBuffer) {
                        const dataView = new DataView(message);
                        const type = dataView.getUint8(0); // 1 for video, 2 for audio

                        // The rest of the data is the raw frame
                        const frameData = message.slice(1);

                        if (type === 1) { // Video
                            if (videoSourceBuffer && !videoSourceBuffer.updating) {
                                videoSourceBuffer.appendBuffer(frameData);
                            } else {
                                videoQueue.push(frameData);
                            }
                        } else if (type === 2) { // Audio
                            if (audioSourceBuffer && !audioSourceBuffer.updating) {
                                audioSourceBuffer.appendBuffer(frameData);
                            } else {
                                audioQueue.push(frameData);
                            }
                        }

                        // Start playback if we have buffered enough
                        if (remoteVideo.paused && remoteVideo.buffered.length > 0 && remoteVideo.buffered.end(0) > 0.1) {
                            remoteVideo.play().catch(e => console.error("Play failed:", e));
                        }
                    }
                } catch (e) { console.error('Message processing error:', e); }
            });

            context.start(castReceiverOptions);
        }
    </script>
</body>
</html>
